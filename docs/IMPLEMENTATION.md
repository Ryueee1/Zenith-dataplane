# Zenith Implementation Documentation

**Author:** Wahyu Ardiansyah  
**Version:** 0.2.0  
**Date:** 2024-12-09  

---

## Table of Contents

1. [Project Overview](#project-overview)
2. [Architecture](#architecture)
3. [Implementation Details](#implementation-details)
4. [Testing & Quality Assurance](#testing--quality-assurance)
5. [Benchmark Results](#benchmark-results)
6. [API Reference](#api-reference)
7. [Deployment Guide](#deployment-guide)

---

## 1. Project Overview

### Vision

Zenith is a high-performance data ingestion and dataplane engine designed for ML/streaming workloads. It reduces I/O bottlenecks and improves end-to-end training throughput.

### Core Goals

- **2-5x faster data loading** than native PyTorch DataLoader
- **Sub-millisecond batch latencies** for GPU utilization optimization
- **Zero-copy memory sharing** via Apache Arrow integration
- **Drop-in replacement** for existing ML frameworks

### Key Features (v0.2.0)

| Feature | Status | Description |
|---------|--------|-------------|
| Zero-copy Arrow IPC | âœ… Complete | Direct memory access without serialization |
| Parquet/CSV/Arrow loading | âœ… Complete | Multi-format support |
| PyTorch adapter | âœ… Complete | `from zenith.torch import DataLoader` |
| Batch iteration | âœ… Complete | Efficient batch processing |
| Multi-worker prefetch | ğŸ”„ In Progress | Parallel data loading |
| WebDataset support | ğŸ“‹ Planned | TAR shard streaming |
| S3 adapter | ğŸ“‹ Planned | Cloud storage integration |

---

## 2. Architecture

### System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Python SDK Layer                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ zenith.load â”‚  â”‚ DataLoader  â”‚  â”‚ zenith.torch.DataLoader â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚ FFI (ctypes)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Rust Core Engine                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ zenith-core    â”‚  â”‚ cpu-runtime  â”‚  â”‚ dataloader      â”‚  â”‚
â”‚  â”‚ (FFI + Engine) â”‚  â”‚ (NUMA/SIMD)  â”‚  â”‚ (Arrow/Parquet) â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Component Breakdown

| Component | Language | Purpose |
|-----------|----------|---------|
| `core/` | Rust | FFI bindings, engine coordination |
| `zenith-runtime-cpu/` | Rust | CPU runtime, NUMA, SIMD, DataLoader |
| `zenith-scheduler/` | Rust | Job scheduling (SLURM alternative) |
| `sdk-python/` | Python | User-facing API |
| `bench/` | Python/Bash | Benchmark suite |

---

## 3. Implementation Details

### 3.1 Rust Core DataLoader

**File:** `zenith-runtime-cpu/src/dataloader.rs`

```rust
pub struct DataLoader {
    config: LoaderConfig,
    source: DataSource,
    schema: Option<Arc<Schema>>,
    cached_batches: RwLock<Option<Vec<RecordBatch>>>,
}

impl DataLoader {
    pub fn load(&self) -> Result<BatchIterator, DataLoaderError>;
    pub fn load_parquet(&self, path: &str) -> Result<...>;
    pub fn load_csv(&self, path: &str) -> Result<...>;
    pub fn load_arrow_ipc(&self, path: &str) -> Result<...>;
}
```

**Features:**
- Zero-copy Arrow IPC reading
- Automatic format detection
- Result caching for small datasets (<100MB)
- Batch iteration support

### 3.2 Python SDK

**File:** `sdk-python/zenith/__init__.py`

```python
import zenith

# Simple loading
data = zenith.load("train.parquet")

# DataLoader usage
loader = zenith.DataLoader("data/", batch_size=64)

# Job scheduling
@zenith.job(gpus=4)
def train(): ...
zenith.submit(train)
```

### 3.3 FFI Safety

**File:** `core/src/lib.rs`

All FFI functions wrapped with `catch_unwind` to prevent Rust panics from crashing Python:

```rust
#[no_mangle]
pub extern "C" fn zenith_init(config: *const c_char) -> i32 {
    let result = std::panic::catch_unwind(AssertUnwindSafe(|| {
        // ... implementation
    }));
    
    match result {
        Ok(r) => r,
        Err(_) => ffi_error::FFI_PANIC,
    }
}
```

### 3.4 Input Validation

**File:** `core/src/validation.rs`

Comprehensive validation for security:

```rust
pub struct Validator {
    forbidden_patterns: HashSet<String>,
}

impl Validator {
    pub fn validate_job_name(&self, name: &str) -> ValidationResult<()>;
    pub fn validate_path(&self, path: &str) -> ValidationResult<()>;
    pub fn validate_command(&self, command: &str) -> ValidationResult<()>;
}
```

---

## 4. Testing & Quality Assurance

### 4.1 Test Coverage

| Module | Tests | Status |
|--------|-------|--------|
| zenith-runtime-cpu | 49 tests | âœ… All passing |
| zenith-core | 5 tests | âœ… All passing |
| zenith-scheduler | 10+ tests | âœ… All passing |
| **Total** | **54+ tests** | **100% pass rate** |

### 4.2 Running Tests

```bash
# Run all Rust tests
cargo test

# Run specific package
cargo test -p zenith-runtime-cpu

# Run with output
cargo test -- --nocapture
```

### 4.3 Quality Metrics

| Metric | Standard | Zenith Status |
|--------|----------|---------------|
| Compilation | No errors | âœ… Clean |
| Warnings | Minimal | âœ… 29 (docs only) |
| FFI Safety | catch_unwind | âœ… Implemented |
| Input Validation | Required | âœ… Implemented |

---

## 5. Benchmark Results

### 5.1 Summary

| Metric | Zenith | Improvement |
|--------|--------|-------------|
| Throughput | 1.35M samples/sec | **4.2x vs iterator** |
| Latency p50 | 0.044 ms | Sub-millisecond |
| Latency p99 | 0.074 ms | Ultra-low tail latency |

### 5.2 MVP Criteria

| Criteria | Target | Result | Status |
|----------|--------|--------|--------|
| â‰¥20% throughput improvement | Required | **322%** | âœ… PASS |
| Reproducible benchmarks | Required | Scripts available | âœ… PASS |
| Documentation | Required | Complete | âœ… PASS |

### 5.3 Benchmark Commands

```bash
# Generate datasets
python bench/generate_datasets.py --scale tiny

# Run Zenith benchmark
python bench/zenith/zenith_benchmark.py --duration 10 --batch-size 64

# Full suite
./bench/run_benchmarks.sh --all
```

---

## 6. API Reference

### Python API

```python
# Core functions
zenith.load(path: str) -> pyarrow.Table
zenith.info() -> None

# DataLoader
zenith.DataLoader(source, batch_size=32, shuffle=True)

# Job scheduling
@zenith.job(gpus=1, memory="8GB")
def func(): ...

zenith.submit(func)
zenith.status(job_id)
```

### Rust API

```rust
// DataLoader
pub fn DataLoader::new(source: DataSource, config: LoaderConfig) -> Self;
pub fn DataLoader::load(&self) -> Result<BatchIterator, DataLoaderError>;

// BatchIterator
impl Iterator for BatchIterator {
    type Item = RecordBatch;
    fn next(&mut self) -> Option<RecordBatch>;
}
```

---

## 7. Deployment Guide

### 7.1 Installation

```bash
# From source
git clone https://github.com/vibeswithkk/Zenith-dataplane.git
cd Zenith-dataplane
cargo build --release
pip install -e sdk-python/
```

### 7.2 Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `ZENITH_CORE_LIB` | Path to libzenith_core.so | Auto-detect |
| `ZENITH_LOG_LEVEL` | Logging verbosity | `info` |
| `ZENITH_NUM_WORKERS` | Default worker count | `4` |

### 7.3 Docker

```dockerfile
FROM rust:1.75 as builder
WORKDIR /app
COPY . .
RUN cargo build --release

FROM python:3.12-slim
COPY --from=builder /app/target/release/libzenith_core.so /usr/lib/
COPY sdk-python/ /app/sdk-python/
RUN pip install -e /app/sdk-python/
```

---

## Appendix

### File Structure

```
zenith-dataplane/
â”œâ”€â”€ core/                     # Rust core with FFI
â”œâ”€â”€ zenith-runtime-cpu/       # CPU runtime (DataLoader, NUMA, SIMD)
â”œâ”€â”€ zenith-runtime-gpu/       # GPU runtime (CUDA, TensorRT)
â”œâ”€â”€ zenith-scheduler/         # Job scheduler
â”œâ”€â”€ sdk-python/               # Python SDK
â”œâ”€â”€ bench/                    # Benchmark suite
â”œâ”€â”€ docs/                     # Documentation
â””â”€â”€ tests/                    # Integration tests
```

### Dependencies

**Rust:**
- arrow: 53.x
- parquet: 53.x  
- tokio: 1.x
- parking_lot: 0.12

**Python:**
- pyarrow: 22.x
- torch: 2.x (optional)

---

*Documentation generated for Zenith v0.2.0*
